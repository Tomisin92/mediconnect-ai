import streamlit as st
import openai
import json
from PIL import Image
import traceback
import os
import psycopg2
from sqlalchemy import create_engine, text
from datetime import datetime
import uuid

# Initialize OpenAI client - Streamlit Cloud compatible
OPENAI_API_KEY = ""
try:
    # Try Streamlit secrets first (for cloud deployment)
    OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")
except:
    # Fallback to environment variable (for local development)
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

if OPENAI_API_KEY:
    openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
else:
    openai_client = None

# Database connection
@st.cache_resource
def get_database_connection():
    """Connect directly to PostgreSQL from Streamlit"""
    try:
        # Use your Docker PostgreSQL connection
        DATABASE_URL = "postgresql://mediconnect_user:mediconnect_secure_password_2025@localhost:5435/mediconnect"
        engine = create_engine(DATABASE_URL)
        # Test connection
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        return engine
    except Exception as e:
        st.error(f"Database connection failed: {e}")
        return None

# Database functions
def save_consultation_to_db(consultation_data):
    """Save consultation directly to PostgreSQL"""
    engine = get_database_connection()
    if not engine:
        return False
    
    try:
        with engine.connect() as conn:
            consultation_query = text("""
                INSERT INTO consultations 
                (consultation_id, symptoms, language, diagnosis, primary_diagnosis, 
                 confidence_score, urgency_level, recommendations, status, created_at, completed_at)
                VALUES 
                (:consultation_id, :symptoms, :language, :diagnosis, :primary_diagnosis,
                 :confidence_score, :urgency_level, :recommendations, :status, :created_at, :completed_at)
                ON CONFLICT (consultation_id) 
                DO UPDATE SET
                    symptoms = EXCLUDED.symptoms,
                    diagnosis = EXCLUDED.diagnosis,
                    primary_diagnosis = EXCLUDED.primary_diagnosis,
                    confidence_score = EXCLUDED.confidence_score,
                    urgency_level = EXCLUDED.urgency_level,
                    recommendations = EXCLUDED.recommendations,
                    status = EXCLUDED.status,
                    completed_at = EXCLUDED.completed_at
            """)
            
            conn.execute(consultation_query, consultation_data)
            conn.commit()
            return True
    except Exception as e:
        st.error(f"Error saving consultation: {e}")
        return False

def save_ai_question_to_db(question_data):
    """Save AI question directly to PostgreSQL"""
    engine = get_database_connection()
    if not engine:
        return False
    
    try:
        with engine.connect() as conn:
            question_query = text("""
                INSERT INTO ai_questions 
                (consultation_id, question_text, question_language, question_order, 
                 user_response, created_at)
                VALUES 
                (:consultation_id, :question_text, :question_language, :question_order,
                 :user_response, :created_at)
                ON CONFLICT (consultation_id, question_order)
                DO UPDATE SET
                    user_response = EXCLUDED.user_response,
                    question_text = EXCLUDED.question_text
            """)
            
            conn.execute(question_query, question_data)
            conn.commit()
            return True
    except Exception as e:
        st.error(f"Error saving AI question: {e}")
        return False

def display_database_status():
    """Show database connection status in sidebar"""
    engine = get_database_connection()
    if engine:
        try:
            with engine.connect() as conn:
                result = conn.execute(text("SELECT COUNT(*) FROM consultations"))
                count = result.scalar()
                st.sidebar.success(f"üóÑÔ∏è Database Connected: {count} consultations")
                
                # Show recent activity
                result = conn.execute(text("""
                    SELECT COUNT(*) FROM consultations 
                    WHERE DATE(created_at) = CURRENT_DATE
                """))
                today_count = result.scalar()
                st.sidebar.info(f"üìÖ Today's consultations: {today_count}")
                return True
        except Exception as e:
            st.sidebar.error(f"üóÑÔ∏è Database Error: {str(e)}")
            return False
    else:
        st.sidebar.error("üóÑÔ∏è Database Not Connected")
        return False

# Translation dictionary (keeping your existing translations)
TRANSLATIONS = {
    "English": {
        "title": "üè• MediConnect AI",
        "subtitle": "Interactive AI Healthcare for Rural Nigeria",
        "language_header": "üåç Language Selection",
        "consultation_header": "ü©∫ Interactive Medical Consultation", 
        "start_consultation": "Start New Consultation",
        "your_response": "Your Response:",
        "ai_questions": "Questions for you:",
        "send_response": "Send Response",
        "diagnosis_ready": "‚úÖ Diagnosis Complete",
        "new_consultation": "Start New Consultation",
        "consultation_progress": "Consultation Progress",
        "questions_for_you": "Questions for you:",
        "type_response": "Type your response here...",
        "example_scenarios": "Example Patient Scenarios",
        "try_scenarios": "Try this consultation starter:",
        "system_impact": "System Impact",
        "interactive_consultations": "Interactive Consultations",
        "questions_asked": "Questions Asked by AI",
        "diagnostic_accuracy": "Diagnostic Accuracy",
        "health_worker_training": "Health Worker Training",
        "with_questions": "with questions",
        "improvement_skills": "improvement in skills",
        "diagnosis_results": "üéØ Diagnosis Results",
        "primary_diagnosis": "Primary Diagnosis:",
        "confidence": "Confidence:",
        "urgency_level": "Urgency Level:",
        "recommendations": "üíä Recommendations",
        "immediate_actions": "Immediate Actions:",
        "no_diagnoses_yet": "No diagnoses yet",
        "ai_confidence": "AI confidence",
        "active": "active",
        "this_session": "this session",
        "exchanges": "exchanges", 
        "total_turns": "total turns",
        "session_progress": "Session Progress",
        "backend_error": "Backend Connection Error",
        "ai_response": "AI Response:",
        "processing": "Processing your response...",
        "error_occurred": "An error occurred",
        "debug_info": "Debug Information",
        "request_data": "Request Data",
        "response_data": "Response Data",
        "final_diagnosis": "üìã Final Medical Assessment",
        "conversation_history": "üí¨ Conversation History",
        "initial_greeting": "Hello! I'm Dr. MediConnect AI. Please describe the patient's symptoms and I'll provide a comprehensive diagnosis.",
        "question_symptoms": "What symptoms is the patient experiencing?",
        "question_when_started": "When did these symptoms start?",
        "question_severity": "How severe are the symptoms?"
    },
    "Hausa": {
        "title": "üè• MediConnect AI",
        "subtitle": "Mu'amalar AI ta kiwon lafiya don karkarar Najeriya",
        "language_header": "üåç Zabin Harshe",
        "consultation_header": "ü©∫ Shawarwarin Likita ta AI",
        "start_consultation": "Fara Sabon Shawara",
        "your_response": "Amsarku:",
        "ai_questions": "Tambayoyin AI gare ku:",
        "send_response": "Aika Amsa",
        "diagnosis_ready": "‚úÖ Ganewar Ya Kamala",
        "new_consultation": "Fara Sabon Shawara",
        "consultation_progress": "Ci gaban Shawara",
        "questions_for_you": "Tambayoyi gare ku:",
        "type_response": "Rubuta amsarku a nan...",
        "example_scenarios": "Misalan Yanayin Majinyaci",
        "try_scenarios": "Gwada wannan mafarin shawara:",
        "system_impact": "Tasirin Tsarin",
        "interactive_consultations": "Shawarwarin Mu'amala",
        "questions_asked": "Tambayoyin da AI ya yi",
        "diagnostic_accuracy": "Daidaiton Ganewar",
        "health_worker_training": "Horar Ma'aikatan Lafiya",
        "with_questions": "da tambayoyi",
        "improvement_skills": "ci gaba a ∆ôwarewa",
        "diagnosis_results": "üéØ Sakamakon Ganewar",
        "primary_diagnosis": "Babban Ganewar:",
        "confidence": "Tabbas:",
        "urgency_level": "Matakin Gaggawa:",
        "recommendations": "üíä Shawarwari",
        "immediate_actions": "Ayyukan Gaggawa:",
        "no_diagnoses_yet": "Babu ganewar tukuna",
        "ai_confidence": "Amincewar AI",
        "active": "mai aiki",
        "this_session": "wannan zaman",
        "exchanges": "musayar",
        "total_turns": "jimillar juyowa",
        "session_progress": "Ci gaban Zaman",
        "backend_error": "Kuskuren Ha…óin Backend",
        "ai_response": "Amsar AI:",
        "processing": "Ana sarrafa amsarku...",
        "error_occurred": "Kuskure ya faru",
        "debug_info": "Bayanan Debug",
        "request_data": "Bayanan Bu∆ôata",
        "response_data": "Bayanan Amsa",
        "final_diagnosis": "üìã Cikakkiyar Kimantawa ta Likitanci",
        "conversation_history": "üí¨ Tarihin Zance",
        "initial_greeting": "Sannu! Ni ne Dokta MediConnect AI. Don Allah ka bayyana alamun majinyaci zan ba da cikakkiyar ganewar asali.",
        "question_symptoms": "Wane alamomi majinyaci yake fuskanta?",
        "question_when_started": "Yaushe wa…óannan alamun suka fara?",
        "question_severity": "Yaya tsananin alamun?"
    },
    "Yoruba": {
        "title": "üè• MediConnect AI",
        "subtitle": "Ibaraenisoro AI ilera fun awon agbegbe Naijiria",
        "language_header": "üåç Yiyan Ede",
        "consultation_header": "ü©∫ Ibaraenisoro Dokita AI",
        "start_consultation": "Bere Ibaraenisoro Tuntun",
        "your_response": "Idahun Yin:",
        "ai_questions": "Awon ibeere AI fun yin:",
        "send_response": "Fi Idahun Ran≈°e",
        "diagnosis_ready": "‚úÖ Iwadii Ti Pari",
        "new_consultation": "Bere Ibaraenisoro Tuntun",
        "consultation_progress": "Il·ªçsiwaju Ibaraenisoro",
        "questions_for_you": "Awon ibeere fun yin:",
        "type_response": "T·∫π idahun yin nibi...",
        "example_scenarios": "Awon Apeere Ipo Alaisan",
        "try_scenarios": "Gbiyanju mafari ibaraenisoro yii:",
        "system_impact": "Ipa Eto",
        "interactive_consultations": "Awon Ibaraenisoro Aj·ªç·π£ep·ªç",
        "questions_asked": "Awon Ibeere ti AI Beere",
        "diagnostic_accuracy": "·ªågb·ªçn Iwadii",
        "health_worker_training": "Ik·∫πk·ªç O·π£i·π£·∫π Ilera",
        "with_questions": "p·∫πlu awon ibeere",
        "improvement_skills": "il·ªçsiwaju ni awon ·ªçgb·ªçn",
        "diagnosis_results": "üéØ Awon Abajade Iwadii",
        "primary_diagnosis": "Iwadii Ak·ªçk·ªç:",
        "confidence": "Igbagb·ªç:",
        "urgency_level": "Ipele Kiakia:",
        "recommendations": "üíä Awon Im·ªçran",
        "immediate_actions": "Awon I·π£e Kiakia:",
        "no_diagnoses_yet": "Ko si awon iwadii sib·∫π",
        "ai_confidence": "Igb·∫πk·∫πle AI",
        "active": "ti n·π£i·π£·∫π",
        "this_session": "i·π£esi yii",
        "exchanges": "awon pa·π£ipaar·ªç",
        "total_turns": "lapap·ªç awon yipo",
        "session_progress": "Il·ªçsiwaju I·π£esi",
        "backend_error": "A·π£i·π£e Asop·ªç Backend",
        "ai_response": "Idahun AI:",
        "processing": "N ·π£i·π£·∫π lori idahun yin...",
        "error_occurred": "A·π£i·π£e kan waye",
        "debug_info": "Alaye Debug",
        "request_data": "Data Ibeere",
        "response_data": "Data Idahun",
        "final_diagnosis": "üìã I·π£iro Ilera Pipe",
        "conversation_history": "üí¨ Itan Ibaraenisoro",
        "initial_greeting": "Bawo! Emi ni Dokita MediConnect AI. J·ªçw·ªç ·π£apejuwe awon ami aisan alaisan, emi yoo fun yin ni iwadii pipe.",
        "question_symptoms": "Awon ami aisan wo ni alaisan n ni?",
        "question_when_started": "Nigbati wo ni awon ami aisan b·∫πr·∫π?",
        "question_severity": "Bawo ni awon ami aisan ·π£e le to?"
    },
    "Igbo": {
        "title": "üè• MediConnect AI",
        "subtitle": "Mkpar·ªãta ·ª•ka AI ah·ª•ike maka ime obodo Na·ªãjir·ªãa",
        "language_header": "üåç Nh·ªçr·ªç As·ª•s·ª•",
        "consultation_header": "ü©∫ Mkpar·ªãta ·ª•ka D·ªçk·ªãta AI",
        "start_consultation": "Malite Mkpar·ªãta ·ª§ka ·ªåh·ª•r·ª•",
        "your_response": "Nzaghachi G·ªã:",
        "ai_questions": "Aj·ª•j·ª• AI maka g·ªã:",
        "send_response": "Ziga Nzaghachi",
        "diagnosis_ready": "‚úÖ Nch·ªçp·ª•ta Zuru Ezu",
        "new_consultation": "Malite Mkpar·ªãta ·ª§ka ·ªåh·ª•r·ª•",
        "consultation_progress": "·ªåganihu Mkpar·ªãta ·ª§ka",
        "questions_for_you": "Aj·ª•j·ª• maka g·ªã:",
        "type_response": "Dee nzaghachi g·ªã ebe a...",
        "example_scenarios": "·ªåm·ª•maat·ª• ·ªån·ªçd·ª• Onye ·ªår·ªãa",
        "try_scenarios": "Nwalee mmalite mkpar·ªãta ·ª•ka a:",
        "system_impact": "Mmet·ª•ta Sistem·ª•",
        "interactive_consultations": "Mkpar·ªãta ·ª§ka Mmek·ªçr·ªãta",
        "questions_asked": "Aj·ª•j·ª• AI J·ª•r·ª•",
        "diagnostic_accuracy": "Izi Ezi Nch·ªçp·ª•ta",
        "health_worker_training": "·ªåz·ª•z·ª• Nd·ªã ·ªår·ª• Ah·ª•ike",
        "with_questions": "na aj·ª•j·ª•",
        "improvement_skills": "mmelite na nk√†",
        "diagnosis_results": "üéØ Nsonaaz·ª• Nch·ªçp·ª•ta",
        "primary_diagnosis": "Nch·ªçp·ª•ta Mb·ª•:",
        "confidence": "Nt·ª•kwas·ªã Obi:",
        "urgency_level": "·ªåkwa Ngwa Ngwa:",
        "recommendations": "üíä Nt·ª•ziaka",
        "immediate_actions": "Omume Ngwa Ngwa:",
        "no_diagnoses_yet": "Enwebegh·ªã nch·ªçp·ª•ta ka",
        "ai_confidence": "Nt·ª•kwas·ªã obi AI",
        "active": "na-ar·ª• ·ªçr·ª•",
        "this_session": "nn·ªçk·ªç a",
        "exchanges": "mgbanwe",
        "total_turns": "ng·ª•k·ªçta nt·ª•ghar·ªã",
        "session_progress": "·ªåganihu Nn·ªçk·ªç",
        "backend_error": "Njehie Njik·ªç Backend",
        "ai_response": "Nzaghachi AI:",
        "processing": "Na-ahazi nzaghachi g·ªã...",
        "error_occurred": "Njehie mere",
        "debug_info": "Ozi Debug",
        "request_data": "Data Ar·ªãr·ªã·ªç",
        "response_data": "Data Nzaghachi",
        "final_diagnosis": "üìã Nyocha Ah·ª•ike Zuru Ezu",
        "conversation_history": "üí¨ Ak·ª•k·ªç Mkpar·ªãta ·ª§ka",
        "initial_greeting": "Ndewo! Ab·ª• m D·ªçk·ªãta MediConnect AI. Biko k·ªçwaa ihe mgba√†m√† onye ·ªçr·ªãa, m ga-enye g·ªã nch·ªçp·ª•ta zuru ezu.",
        "question_symptoms": "Kedu ihe mgba√†m√† onye ·ªçr·ªãa na-enwe?",
        "question_when_started": "Oleizi ka ihe mgba√†m√† nd·ªã a malitere?",
        "question_severity": "Kedu ka ihe mgba√†m√† nd·ªã ah·ª• si sie ike?"
    }
}

def get_text(key, language="English"):
    """Get translated text based on selected language"""
    return TRANSLATIONS[language].get(key, TRANSLATIONS["English"][key])

# Page configuration
st.set_page_config(
    page_title="MediConnect AI - Interactive Healthcare",
    page_icon="üè•",
    layout="wide"
)

# Custom CSS for better styling (keeping your existing styles)
st.markdown("""
<style>
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border-left: 4px solid #0084ff;
    }
    .user-message {
        background-color: #f0f2f6;
        border-left-color: #28a745;
    }
    .ai-message {
        background-color: #e3f2fd;
        border-left-color: #2196f3;
    }
    .diagnosis-container {
        background: linear-gradient(135deg, #e8f5e8 0%, #f0f8ff 100%);
        padding: 2rem;
        border-radius: 1rem;
        border: 2px solid #4caf50;
        margin: 1.5rem 0;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    .diagnosis-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2e7d32;
        margin-bottom: 1rem;
        text-align: center;
    }
    .diagnosis-item {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border-left: 4px solid #4caf50;
    }
    .recommendation-item {
        background-color: #fff3e0;
        padding: 0.8rem;
        border-radius: 0.5rem;
        margin-bottom: 0.5rem;
        border-left: 3px solid #ff9800;
    }
    .urgency-high {
        background-color: #ffebee;
        border-left-color: #f44336;
        color: #c62828;
    }
    .urgency-moderate {
        background-color: #fff8e1;
        border-left-color: #ff9800;
        color: #ef6c00;
    }
    .urgency-low {
        background-color: #e8f5e8;
        border-left-color: #4caf50;
        color: #2e7d32;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
def initialize_session_state():
    """Initialize all session state variables"""
    if 'consultation_id' not in st.session_state:
        st.session_state.consultation_id = None
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    if 'consultation_active' not in st.session_state:
        st.session_state.consultation_active = False
    if 'total_consultations' not in st.session_state:
        st.session_state.total_consultations = 0
    if 'total_questions' not in st.session_state:
        st.session_state.total_questions = 0
    if 'total_diagnoses' not in st.session_state:
        st.session_state.total_diagnoses = 0
    if 'current_questions' not in st.session_state:
        st.session_state.current_questions = 0
    if 'debug_mode' not in st.session_state:
        st.session_state.debug_mode = False
    if 'final_diagnosis' not in st.session_state:
        st.session_state.final_diagnosis = None

# Initialize session state
initialize_session_state()

def get_openai_diagnosis(conversation_text, language="english"):
    """Get medical diagnosis directly from OpenAI"""
    if not openai_client:
        return {
            "primary_diagnosis": "OpenAI API key not configured",
            "confidence": 0.0,
            "urgency": "MODERATE",
            "recommendations": ["Please configure OpenAI API key in Streamlit secrets"],
            "clinical_reasoning": "API key required"
        }
    
    medical_prompt = f"""You are an expert medical doctor. A patient presents with these symptoms:

{conversation_text}

Provide a medical diagnosis in JSON format. Be specific and accurate.

For example, if patient has diarrhea and vomiting for 3 weeks:
- This is chronic gastroenteritis, possibly IBD, parasitic infection, or malabsorption
- NOT acute viral gastroenteritis (that lasts days, not weeks)
- Requires specific investigation and treatment

Respond in {language} with this exact JSON format:
{{
    "primary_diagnosis": "Specific diagnosis based on symptoms",
    "confidence": 0.80,
    "urgency": "LOW/MODERATE/HIGH/CRITICAL",
    "recommendations": [
        "Specific recommendation 1 with dosages if applicable",
        "Specific recommendation 2 with clear instructions", 
        "Specific recommendation 3 with monitoring guidelines",
        "Specific recommendation 4 with follow-up criteria",
        "Specific recommendation 5 with patient education"
    ],
    "clinical_reasoning": "Brief explanation of diagnosis"
}}"""

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {
                    "role": "system",
                    "content": f"You are a medical specialist. Respond only with valid JSON in {language}. No additional text."
                },
                {
                    "role": "user", 
                    "content": medical_prompt
                }
            ],
            temperature=0.1,
            max_tokens=800,
            response_format={ "type": "json_object" }
        )
        
        ai_response = response.choices[0].message.content.strip()
        diagnosis_data = json.loads(ai_response)
        
        # Ensure all required fields
        if not diagnosis_data.get("primary_diagnosis"):
            diagnosis_data["primary_diagnosis"] = "Medical assessment completed"
        if not diagnosis_data.get("confidence"):
            diagnosis_data["confidence"] = 0.75
        if not diagnosis_data.get("urgency"):
            diagnosis_data["urgency"] = "MODERATE"
        if not diagnosis_data.get("recommendations"):
            diagnosis_data["recommendations"] = ["Follow medical advice", "Monitor symptoms", "Return if worsening"]
            
        return diagnosis_data
        
    except Exception as e:
        st.error(f"OpenAI Error: {str(e)}")
        return {
            "primary_diagnosis": f"Assessment limited due to API error: {str(e)[:100]}",
            "confidence": 0.60,
            "urgency": "MODERATE",
            "recommendations": [
                "Seek direct medical consultation",
                "Monitor symptoms closely", 
                "Return if symptoms worsen",
                "Consider emergency care if severe",
                "Follow up with healthcare provider"
            ],
            "clinical_reasoning": "Limited by system error"
        }

def get_openai_questions(conversation_text, language="english", exchange_number=0):
    """Get follow-up questions directly from OpenAI - All questions AI generated"""
    if not openai_client:
        return {
            "questions": ["OpenAI API not available - Please configure API key"],
            "ai_response": "Cannot generate questions without OpenAI API access."
        }
    
    # Create context-aware prompts based on exchange number
    question_contexts = {
        0: "basic patient demographics, symptom onset, and initial presentation",
        1: "medical history, current medications, and recent exposures or activities", 
        2: "symptom severity, family medical history, and known allergies",
        3: "associated symptoms, recent lifestyle changes, and functional impact"
    }
    
    context = question_contexts.get(exchange_number, "additional clinical details for comprehensive assessment")
    
    question_prompt = f"""You are an expert medical doctor conducting a thorough consultation. Based on this patient information: 

{conversation_text}

This is consultation exchange number {exchange_number + 1}. Focus on gathering information about {context}.

Generate 3-4 intelligent, specific medical follow-up questions in {language} that will help you make an accurate diagnosis. 

Guidelines for this exchange:
- Exchange 1: Focus on basic demographics (age, gender), timeline of symptoms, fever status, initial severity
- Exchange 2: Explore past medical history, current medications, recent travel/exposures, lifestyle factors
- Exchange 3: Assess symptom severity scales, family history, allergies, and red flag symptoms
- Exchange 4: Investigate associated symptoms, functional impact, recent changes in health

Make the questions:
1. Clinically relevant and specific to the patient's presentation
2. Progressive - building on previous answers
3. Appropriate for the consultation stage
4. Clear and easy to understand in {language}

Respond with this exact JSON format:
{{
    "questions": [
        "Specific medical question 1 in {language}",
        "Specific medical question 2 in {language}",
        "Specific medical question 3 in {language}",
        "Specific medical question 4 in {language}"
    ],
    "ai_response": "Professional medical response in {language} explaining why you need this specific information"
}}"""

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {
                    "role": "system",
                    "content": f"You are an expert medical doctor conducting consultations in {language}. Generate intelligent, context-specific diagnostic questions. Always ask 3-4 questions. Respond only with valid JSON."
                },
                {
                    "role": "user",
                    "content": question_prompt
                }
            ],
            temperature=0.4,  # Slightly higher for more varied questions
            max_tokens=600,   # More tokens for detailed questions
            response_format={ "type": "json_object" }
        )
        
        ai_response = response.choices[0].message.content.strip()
        questions_data = json.loads(ai_response)
        
        # Ensure we have questions
        if not questions_data.get("questions") or len(questions_data["questions"]) == 0:
            raise ValueError("No questions generated")
            
        # Ensure we have 3-4 questions
        if len(questions_data["questions"]) < 3:
            # If less than 3, ask OpenAI to generate more
            return get_openai_questions_retry(conversation_text, language, exchange_number)
            
        return questions_data
        
    except Exception as e:
        st.error(f"Error generating questions: {str(e)}")
        # If OpenAI fails, try one more time with a simpler prompt
        return get_openai_questions_retry(conversation_text, language, exchange_number)

def get_openai_questions_retry(conversation_text, language, exchange_number):
    """Retry with simpler prompt if first attempt fails"""
    if not openai_client:
        return {
            "questions": ["OpenAI API not available"],
            "ai_response": "Cannot generate questions without OpenAI API."
        }
    
    simple_prompt = f"""Based on patient symptoms: {conversation_text}

Ask 3 medical questions in {language} for consultation round {exchange_number + 1}.

JSON format:
{{
    "questions": ["Question 1", "Question 2", "Question 3"],
    "ai_response": "Brief explanation in {language}"
}}"""

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": f"Medical doctor asking questions in {language}. JSON only."},
                {"role": "user", "content": simple_prompt}
            ],
            temperature=0.3,
            max_tokens=400,
            response_format={ "type": "json_object" }
        )
        
        return json.loads(response.choices[0].message.content.strip())
        
    except Exception as e:
        # Last resort - return a basic structure
        st.error(f"OpenAI question generation failed: {str(e)}")
        return {
            "questions": [
                f"Could not generate questions - OpenAI error: {str(e)[:50]}...",
                "Please check your OpenAI API key and try again",
                "Or restart the consultation"
            ],
            "ai_response": "Technical error occurred. Please restart consultation."
        }

def start_new_consultation(language):
    """Start a new consultation with direct OpenAI - Fixed language support"""
    import uuid
    consultation_id = str(uuid.uuid4())
    
    # Get initial greeting and questions using the get_text function
    initial_greeting = get_text("initial_greeting", language)
    
    initial_questions = [
        get_text("question_symptoms", language),
        get_text("question_when_started", language),
        get_text("question_severity", language)
    ]
    
    return {
        "consultation_id": consultation_id,
        "ai_response": initial_greeting,
        "questions": initial_questions,
        "status": "consultation_started"
    }

def continue_consultation(consultation_id, user_input, language, has_image=False, image_description=""):
    """Continue consultation with direct OpenAI - Enhanced with more follow-up questions"""
    
    # Get conversation history
    conversation_text = ""
    for turn in st.session_state.conversation_history:
        if turn["type"] == "user":
            conversation_text += f"Patient: {turn['content']} "
    
    # Add current input
    conversation_text += f"Patient: {user_input} "
    
    # Add image info if present
    if has_image and image_description:
        conversation_text += f"[Medical Image: {image_description}] "
    
    # Count user exchanges
    user_exchanges = len([turn for turn in st.session_state.conversation_history if turn["type"] == "user"])
    
    # Decide whether to ask questions or provide diagnosis
    # Ask 3-4 rounds of questions before diagnosing
    should_diagnose = user_exchanges >= 3  # Diagnose after 3-4 exchanges
    
    if should_diagnose:
        # Get diagnosis from OpenAI
        diagnosis = get_openai_diagnosis(conversation_text, language.lower())
        
        response_texts = {
            'English': "Based on the symptoms described, here is my medical assessment:",
            'Hausa': "Bisa ga alamun da aka bayyana, ga kimantawa ta likitanci:",
            'Yoruba': "Ni ibamu lori awon ami aisan ti a so, eyi ni i·π£iro mi ti ilera:",
            'Igbo': "Dabere na ihe mgba√†m√† ak·ªçwara, nke a b·ª• nyocha ah·ª•ike m:"
        }
        
        return {
            "type": "diagnosis",
            "ai_response": response_texts.get(language, response_texts['English']),
            "diagnosis": diagnosis,
            "consultation_complete": True
        }
    else:
        # Get follow-up questions from OpenAI
        questions_data = get_openai_questions(conversation_text, language.lower(), user_exchanges)
        
        return {
            "type": "questions",
            "ai_response": questions_data["ai_response"],
            "questions": questions_data["questions"],
            "consultation_continues": True
        }

def reset_consultation():
    """Reset consultation state"""
    st.session_state.consultation_id = None
    st.session_state.conversation_history = []
    st.session_state.consultation_active = False
    st.session_state.current_questions = 0
    st.session_state.final_diagnosis = None

def display_conversation_history(language):
    """Display the conversation history in a chat-like format with proper language support"""
    for i, turn in enumerate(st.session_state.conversation_history):
        if turn["type"] == "ai":
            with st.chat_message("assistant", avatar="ü§ñ"):
                st.markdown(f"**{get_text('ai_response', language)}**")
                st.write(turn["content"])
                
                if "questions" in turn and turn["questions"]:
                    st.markdown(f"**{get_text('questions_for_you', language)}**")
                    for q in turn["questions"]:
                        st.write(f"‚Ä¢ {q}")
                        
        else:  # user message
            with st.chat_message("user", avatar="üë®‚Äç‚öïÔ∏è"):
                st.markdown(f"**{get_text('your_response', language)}**")
                st.write(turn["content"])

def display_final_diagnosis(diagnosis, language):
    """Display the final diagnosis in a prominent, clear format"""
    
    st.markdown(f"""
    <div class="diagnosis-container">
        <div class="diagnosis-header">{get_text('final_diagnosis', language)}</div>
    </div>
    """, unsafe_allow_html=True)
    
    # Create two columns for diagnosis details
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown(f"### {get_text('diagnosis_results', language)}")
        
        # Primary diagnosis
        st.markdown(f"""
        <div class="diagnosis-item">
            <strong>{get_text('primary_diagnosis', language)}</strong><br>
            {diagnosis.get('primary_diagnosis', 'Not specified')}
        </div>
        """, unsafe_allow_html=True)
        
        # Confidence with progress bar
        confidence = diagnosis.get('confidence', 0)
        st.markdown(f"**{get_text('confidence', language)}**")
        st.progress(confidence)
        st.write(f"**{confidence * 100:.0f}%**")
        
        # Urgency level with color coding
        urgency = diagnosis.get('urgency', 'MODERATE')
        urgency_colors = {
            'LOW': ('üü¢', 'urgency-low'),
            'MODERATE': ('üü°', 'urgency-moderate'), 
            'HIGH': ('üî¥', 'urgency-high'),
            'CRITICAL': ('üö®', 'urgency-high')
        }
        
        icon, css_class = urgency_colors.get(urgency, ('üü°', 'urgency-moderate'))
        
        st.markdown(f"""
        <div class="diagnosis-item {css_class}">
            <strong>{get_text('urgency_level', language)}</strong><br>
            {icon} <strong>{urgency}</strong>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"### {get_text('recommendations', language)}")
        st.markdown(f"**{get_text('immediate_actions', language)}**")
        
        recommendations = diagnosis.get('recommendations', [])
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                st.markdown(f"""
                <div class="recommendation-item">
                    <strong>{i}.</strong> {rec}
                </div>
                """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="recommendation-item">
                <strong>No specific recommendations provided</strong>
            </div>
            """, unsafe_allow_html=True)

# Language selection
st.header("üåç Language Selection / Zabin Harshe / Yiyan Ede / Nh·ªçr·ªç As·ª•s·ª•")
selected_language = st.selectbox(
    "Select Language / Za…ìi Harshe / Yan Ede / H·ªçr·ªç As·ª•s·ª•", 
    ["English", "Hausa", "Yoruba", "Igbo"]
)

# Main interface
st.title(get_text("title", selected_language))
st.subheader(get_text("subtitle", selected_language))

# Debug mode toggle (hidden in sidebar)
with st.sidebar:
    st.session_state.debug_mode = st.checkbox("üîç Debug Mode", value=st.session_state.debug_mode)

# OpenAI connection status
if OPENAI_API_KEY:
    st.success("‚úÖ AI Medical Assistant Ready - OpenAI Direct Mode!")
else:
    st.error("‚ùå OpenAI API key not configured. Please add OPENAI_API_KEY to Streamlit secrets.")
    st.info("üí° Go to app settings ‚Üí Secrets ‚Üí Add: OPENAI_API_KEY = \"your-key-here\"")

# Main consultation interface
st.header(get_text("consultation_header", selected_language))

# Start new consultation section
if not st.session_state.consultation_active:
    # Start consultation button
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if st.button(
            get_text("start_consultation", selected_language), 
            type="primary", 
            use_container_width=True,
            disabled=not OPENAI_API_KEY,
            key="start_consultation_main"
        ):
            with st.spinner(get_text("processing", selected_language)):
                data = start_new_consultation(selected_language)
                
                st.session_state.consultation_id = data["consultation_id"]
                st.session_state.consultation_active = True
                st.session_state.conversation_history = [{
                    "type": "ai",
                    "content": data["ai_response"],
                    "questions": data.get("questions", [])
                }]
                st.session_state.total_consultations += 1
                st.session_state.current_questions = len(data.get("questions", []))
                st.session_state.final_diagnosis = None  # Reset diagnosis
                st.rerun()
    
    with col2:
        if st.button("üîÑ Reset All Data", key="reset_all_data_main"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            initialize_session_state()
            st.rerun()

# Display final diagnosis if consultation is complete
if st.session_state.final_diagnosis and not st.session_state.consultation_active:
    st.markdown("---")
    display_final_diagnosis(st.session_state.final_diagnosis, selected_language)
    
    # Start new consultation button after diagnosis
    st.markdown("---")
    if st.button(get_text("new_consultation", selected_language), type="primary", use_container_width=True, key="new_consultation_after_diagnosis"):
        reset_consultation()
        st.rerun()

# Active consultation interface
if st.session_state.consultation_active:
    
    # Progress indicator
    exchanges_count = len([turn for turn in st.session_state.conversation_history if turn.get("type") == "user"])
    st.info(f"üîÑ {get_text('consultation_progress', selected_language)}: {exchanges_count} {get_text('exchanges', selected_language)}")
    
    # Display conversation history
    if st.session_state.conversation_history:
        st.markdown(f"### {get_text('conversation_history', selected_language)}")
        display_conversation_history(selected_language)
    
    # Check if consultation is complete (has diagnosis)
    last_turn = st.session_state.conversation_history[-1] if st.session_state.conversation_history else None
    consultation_complete = (last_turn and 
                           last_turn.get("type") == "ai" and 
                           "diagnosis" in last_turn and 
                           last_turn["diagnosis"])
    
    if not consultation_complete:
        # Input section for continuing consultation
        st.markdown("---")
        st.markdown(f"### {get_text('your_response', selected_language)}")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            user_input = st.text_area(
                get_text("type_response", selected_language),
                height=100,
                key=f"user_input_{len(st.session_state.conversation_history)}",
                placeholder=get_text("type_response", selected_language)
            )
        
        with col2:
            st.markdown("**üì∏ Medical Image (Optional)**")
            uploaded_image = st.file_uploader(
                "X-ray, skin condition, etc.",
                type=['png', 'jpg', 'jpeg'],
                key=f"image_{len(st.session_state.conversation_history)}"
            )
            
            if uploaded_image:
                st.image(uploaded_image, caption="Medical Image", width=150)
                st.info("üí° AI will analyze this image with your consultation")
        
        # Send response and new consultation buttons
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            if st.button(
                get_text("send_response", selected_language), 
                type="primary", 
                disabled=not user_input.strip(),
                use_container_width=True,
                key="send_response_main"
            ):
                if user_input.strip():
                    with st.spinner(get_text("processing", selected_language)):
                        # Add user input to conversation history
                        st.session_state.conversation_history.append({
                            "type": "user",
                            "content": user_input
                        })
                        
                        # Prepare image description if image uploaded
                        image_description = ""
                        if uploaded_image:
                            image_description = f"Medical image uploaded: {uploaded_image.name}. This appears to be a medical image that should be considered in the diagnosis."
                        
                        # Continue consultation
                        data = continue_consultation(
                            st.session_state.consultation_id,
                            user_input,
                            selected_language,
                            bool(uploaded_image),
                            image_description
                        )
                        
                        if data["type"] == "questions":
                            # More questions
                            st.session_state.conversation_history.append({
                                "type": "ai",
                                "content": data["ai_response"],
                                "questions": data.get("questions", [])
                            })
                            st.session_state.total_questions += len(data.get("questions", []))
                            st.session_state.current_questions = len(data.get("questions", []))
                        else:
                            # Diagnosis ready
                            st.session_state.conversation_history.append({
                                "type": "ai",
                                "content": data["ai_response"],
                                "diagnosis": data.get("diagnosis")
                            })
                            st.session_state.consultation_active = False
                            st.session_state.total_diagnoses += 1
                            # Store final diagnosis for display
                            st.session_state.final_diagnosis = data.get("diagnosis")
                            
                        st.rerun()
        
        with col2:
            if st.button(get_text("new_consultation", selected_language), key="new_consultation_during_active"):
                reset_consultation()
                st.rerun()
        
        with col3:
            if st.button("üîç Toggle Debug", key="toggle_debug_main"):
                st.session_state.debug_mode = not st.session_state.debug_mode
                st.rerun()
    
    else:
        # Consultation complete - store diagnosis and reset
        if last_turn.get("diagnosis"):
            st.session_state.final_diagnosis = last_turn["diagnosis"]
        st.session_state.consultation_active = False
        st.rerun()

# Sidebar with project information and metrics
with st.sidebar:
    st.markdown("---")
    
    # Navigation tabs
    tab_selection = st.radio(
        "Navigation",
        ["üìã Project Summary", "üìä Live Metrics", "üß™ Test Scenarios"],
        label_visibility="collapsed"
    )
    
    if tab_selection == "üìã Project Summary":
        st.markdown("### üè• MediConnect AI")
        st.markdown("*Multilingual AI Medical Consultant for Nigerian Rural Healthcare*")
        
        st.markdown("---")
        
        # The Problem
        st.markdown("#### üéØ The Problem")
        st.markdown("""
        **Rural Nigeria Healthcare Crisis:**
        
        ‚Ä¢ **120 million rural Nigerians** lack access to quality healthcare
        
        ‚Ä¢ **Doctor-to-patient ratio:** 1:5,000+ vs WHO standard of 1:1,000
        
        ‚Ä¢ **Language barriers:** 90% of rural health workers need native language support
        
        ‚Ä¢ **Diagnostic delays:** 72% of preventable deaths due to late/incorrect diagnosis
        
        ‚Ä¢ **Cost barriers:** $50+ for basic consultation
        
        ‚Ä¢ **Geographic isolation:** 2-hour average travel to nearest doctor
        """)
        
        st.markdown("---")
        
        # Our Solution
        st.markdown("#### üöÄ Our Solution")
        st.markdown("""
        **Core Capabilities:**
        
        ‚Ä¢ **High diagnostic accuracy** (powered by GPT-4)
        
        ‚Ä¢ **4 Nigerian languages:** English, Hausa, Yoruba, Igbo with medical terminology
        
        ‚Ä¢ **Interactive consultation:** 2-3 intelligent questions maximum
        
        ‚Ä¢ **Medical image analysis:** X-ray interpretation, skin condition diagnosis, wound assessment
        
        ‚Ä¢ **Comprehensive diagnosis:** 4-5 detailed recommendations per case
        
        ‚Ä¢ **Cloud-ready:** No backend required, direct OpenAI integration
        """)
        
        st.markdown("**Enhanced Diagnosis Results:**")
        st.markdown("""
        ‚Ä¢ **Primary diagnosis** with confidence scoring (70-95%)
        
        ‚Ä¢ **Urgency level** assessment (LOW, MODERATE, HIGH, CRITICAL)
        
        ‚Ä¢ **4-5 immediate actions** for health workers
        
        ‚Ä¢ **Nigerian-specific conditions** (malaria, typhoid, tropical diseases)
        
        ‚Ä¢ **Age-appropriate recommendations** (pediatric, elderly care)
        """)
    
    elif tab_selection == "üìä Live Metrics":
        st.markdown("#### üìà System Performance")
        
        # Calculate current session metrics
        current_questions = st.session_state.current_questions
        current_exchanges = len([turn for turn in st.session_state.conversation_history if turn.get("type") == "user"])
        
        # Calculate diagnostic confidence if available
        latest_confidence = "N/A"
        confidence_delta = get_text('no_diagnoses_yet', selected_language)
        
        if st.session_state.final_diagnosis:
            try:
                confidence = st.session_state.final_diagnosis.get("confidence", 0)
                latest_confidence = f"{confidence * 100:.0f}%"
                confidence_delta = get_text('ai_confidence', selected_language)
            except:
                pass
        
        # Display metrics
        col1, col2 = st.columns(2)
        with col1:
            st.metric(
                get_text('interactive_consultations', selected_language),
                st.session_state.total_consultations,
                delta=f"+{1 if st.session_state.consultation_active else 0} {get_text('active', selected_language)}"
            )
            
        with col2:
            st.metric(
                get_text('questions_asked', selected_language),
                st.session_state.total_questions + current_questions,
                delta=f"+{current_questions} {get_text('this_session', selected_language)}"
            )
        
        st.metric(
            get_text('diagnostic_accuracy', selected_language),
            latest_confidence,
            delta=confidence_delta
        )
        
        st.metric(
            get_text('session_progress', selected_language),
            f"{current_exchanges} {get_text('exchanges', selected_language)}",
            delta=f"{len(st.session_state.conversation_history)} {get_text('total_turns', selected_language)}"
        )
        
        # OpenAI status
        st.markdown("---")
        st.markdown("#### üîß System Status")
        if OPENAI_API_KEY:
            st.success("‚úÖ OpenAI Connected")
        else:
            st.error("‚ùå OpenAI API Key Missing")
        
        # Session info
        if st.session_state.consultation_active:
            st.info(f"üîÑ Active Consultation ID: {st.session_state.consultation_id[:8]}...")
        
        # Final diagnosis status
        if st.session_state.final_diagnosis:
            st.success("‚úÖ Diagnosis Available")
            urgency = st.session_state.final_diagnosis.get('urgency', 'MODERATE')
            st.write(f"Urgency: **{urgency}**")
        
    elif tab_selection == "üß™ Test Scenarios":
        st.markdown("#### üí° Example Test Scenarios")
        st.markdown(f"**{get_text('try_scenarios', selected_language)}**")
        
        # Language-specific test scenarios
        scenarios = {
            "English": [
                "5-year-old child with fever for 3 days and body pain",
                "Adult with severe neck pain and headache since yesterday",
                "Pregnant woman with abdominal pain and vomiting",
                "Elderly person with breathing difficulties and weakness",
                "Child with diarrhea, vomiting and moderate fever"
            ],
            "Hausa": [
                "Yaro mai shekara 5 da zazzabi na kwanaki 3 da ciwon jiki",
                "Babba da tsananin ciwon wuya da ciwon kai tun jiya", 
                "Mace mai juna biyu da ciwon ciki da amai",
                "Dattijo da matsalar numfashi da rauni",
                "Yaro da gudawa, amai da matsakaicin zazzabi"
            ],
            "Yoruba": [
                "·ªåm·ªç ·ªçdun marun ti o ni iba fun ·ªçj·ªç m·∫πta ati ira ara",
                "Agbalagba ti o ni ·ªçr·ªçn gigun nla ati ori gigun lati ana",
                "Obinrin oyun ti o ni inu gigun ati ·ªçgb·∫πl·∫π",
                "Arugbo ti o ni wahala mimi ati ailera",
                "·ªåm·ªç ti o ni inu jij·∫π, ·ªçgb·∫πl·∫π ati iba agbedemeji"
            ],
            "Igbo": [
                "Nwata af·ªç ise nwere ah·ª• ·ªçk·ª• ruo ·ª•b·ªçch·ªã at·ªç na mgbu ah·ª•",
                "Onye okenye nwere nnukwu mgbu olu na isi ·ªçw·ª•wa kemgbe ·ª•nyaah·ª•",
                "Nwany·ªã d·ªã ime nwere mgbu af·ªç na ·ªçgb·ª•gb·ªç",
                "Onye agadi nwere nsogbu iku ume na ad·ªãgh·ªã ike",
                "Nwata nwere af·ªç ·ªçs·ªãsa, ·ªçgb·ª•gb·ªç na ah·ª• ·ªçk·ª• agbata obi"
            ]
        }
        
        test_scenarios = scenarios.get(selected_language, scenarios["English"])
        
        for i, scenario in enumerate(test_scenarios):
            if st.button(f"üìù {scenario}", key=f"scenario_{i}"):
                if not st.session_state.consultation_active:
                    # Start consultation first
                    data = start_new_consultation(selected_language)
                    st.session_state.consultation_id = data["consultation_id"]
                    st.session_state.consultation_active = True
                    st.session_state.conversation_history = [{
                        "type": "ai",
                        "content": data["ai_response"],
                        "questions": data.get("questions", [])
                    }]
                    st.session_state.total_consultations += 1
                    st.session_state.final_diagnosis = None
                    
                # Add scenario as user input
                if st.session_state.consultation_active:
                    st.session_state.conversation_history.append({
                        "type": "user",
                        "content": scenario
                    })
                    
                    # Continue consultation with scenario
                    data = continue_consultation(
                        st.session_state.consultation_id,
                        scenario,
                        selected_language
                    )
                    
                    if data["type"] == "questions":
                        st.session_state.conversation_history.append({
                            "type": "ai",
                            "content": data["ai_response"],
                            "questions": data.get("questions", [])
                        })
                        st.session_state.total_questions += len(data.get("questions", []))
                    else:
                        st.session_state.conversation_history.append({
                            "type": "ai",
                            "content": data["ai_response"],
                            "diagnosis": data.get("diagnosis")
                        })
                        st.session_state.consultation_active = False
                        st.session_state.total_diagnoses += 1
                        st.session_state.final_diagnosis = data.get("diagnosis")
                    
                    st.rerun()
        
        st.markdown("---")
        st.markdown("**üì∏ Medical Imaging AI**")
        st.markdown("‚Ä¢ X-ray interpretation")
        st.markdown("‚Ä¢ Skin condition diagnosis") 
        st.markdown("‚Ä¢ Wound assessment")
        st.markdown("‚Ä¢ Ultrasound analysis")
        st.markdown("‚Ä¢ Laboratory results")
        
        # Quick actions
        st.markdown("---")
        st.markdown("#### ‚ö° Quick Actions")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîÑ Reset Session", key="reset_sidebar"):
                reset_consultation()
                st.rerun()
        
        with col2:
            if st.button("üìä Refresh Metrics", key="refresh_sidebar"):
                st.rerun()

# Footer with additional information
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <h4>üè• MediConnect AI - Bridging Healthcare Gaps in Rural Nigeria</h4>
    <p>Interactive AI-powered medical consultations in local languages</p>
    <p><strong>Languages Supported:</strong> English ‚Ä¢ Hausa ‚Ä¢ Yoruba ‚Ä¢ Igbo</p>
    <p><strong>Features:</strong> Smart Questioning ‚Ä¢ Medical Image Analysis ‚Ä¢ Comprehensive Diagnosis ‚Ä¢ Direct OpenAI</p>
</div>
""", unsafe_allow_html=True)

# Debug information (only show if debug mode is on)
if st.session_state.debug_mode:
    st.markdown("---")
    st.markdown("### üîç Debug Information")
    
    with st.expander("Session State", expanded=False):
        st.json({
            "consultation_id": st.session_state.consultation_id,
            "consultation_active": st.session_state.consultation_active,
            "conversation_length": len(st.session_state.conversation_history),
            "total_consultations": st.session_state.total_consultations,
            "total_questions": st.session_state.total_questions,
            "total_diagnoses": st.session_state.total_diagnoses,
            "openai_api_key_configured": bool(OPENAI_API_KEY),
            "selected_language": selected_language,
            "has_final_diagnosis": bool(st.session_state.final_diagnosis)
        })
    
    with st.expander("Final Diagnosis", expanded=False):
        if st.session_state.final_diagnosis:
            st.json(st.session_state.final_diagnosis)
        else:
            st.write("No final diagnosis yet")
    
    with st.expander("Conversation History", expanded=False):
        for i, turn in enumerate(st.session_state.conversation_history):
            st.write(f"**Turn {i+1} ({turn['type']}):**")
            st.json(turn)
    
    with st.expander("OpenAI Status", expanded=False):
        if OPENAI_API_KEY:
            st.success("‚úÖ OpenAI API Key Configured")
            st.write(f"Key preview: {OPENAI_API_KEY[:8]}...")
        else:
            st.error("‚ùå OpenAI API Key Missing")
            st.info("Add OPENAI_API_KEY to Streamlit secrets")
    
    # Manual OpenAI testing section
    with st.expander("Manual OpenAI Testing", expanded=False):
        st.markdown("#### üß™ Test OpenAI Connection")
        
        if st.button("Test OpenAI Connection", key="test_openai_direct"):
            if not OPENAI_API_KEY:
                st.error("‚ùå No OpenAI API key configured")
            else:
                try:
                    with st.spinner("Testing OpenAI..."):
                        test_response = openai_client.chat.completions.create(
                            model="gpt-4-turbo-preview",
                            messages=[{"role": "user", "content": "Say 'OpenAI test successful'"}],
                            max_tokens=10
                        )
                        result = test_response.choices[0].message.content
                        st.success(f"‚úÖ OpenAI Working: {result}")
                except Exception as e:
                    st.error(f"‚ùå OpenAI Error: {str(e)}")
                    if "insufficient_quota" in str(e).lower():
                        st.info("üí° This usually means you need to add billing to your OpenAI account")
                    elif "invalid_api_key" in str(e).lower():
                        st.info("üí° Check your API key in Streamlit secrets")

# Final status display at bottom
st.markdown("---")
if st.session_state.consultation_active:
    st.info("üîÑ Consultation in progress...")
elif st.session_state.final_diagnosis:
    st.success("‚úÖ Consultation completed - Diagnosis available above")
else:
    st.info("üí° Ready to start a new consultation")